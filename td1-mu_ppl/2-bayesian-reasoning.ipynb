{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/gbdrt/mu-ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_ppl import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Reasoning\n",
    "\n",
    "In a nutshell, Bayesian resonning computes the _posterior_ distribution of a random variable from a _prior_ distribution and _observed_ data.\n",
    "\n",
    "## The coin example \n",
    "\n",
    "The \"hello world\" example for Bayesian reasoning estimates the bias of a coin from a series of observations.\n",
    "The random variable of interest `z` corresponds to the bias to the coin: `z=0.5` is a fair coin, `z = 0` is a coin which always falls tail.\n",
    "We want to compute a distribution of possible values for `z` given a series of observed coin flips.\n",
    "\n",
    "For instance the result of 10 coin flip could be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flips = [0, 1, 0, 0, 0, 0, 1, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Initially, we have no information, `z` could be anything in between $0$ and $1$: the _prior_ distribution is the uniform distribution over $[0, 1]$.\n",
    "But we do know that each coin flip `y_i` follows a Bernoulli distribution parameterized by `z`.\n",
    "Our goal is to estimate $P(z | y_1, y_2, ... y_n)$.\n",
    "\n",
    "### Generative model\n",
    "\n",
    "This exercise can be directly translated into the following mu-PPL program, or _generative model_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin(flips: list[int]) -> float:\n",
    "    z = sample(Uniform(0, 1))\n",
    "    for yi in flips:\n",
    "        observe(Bernoulli(z), yi)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `observe(d, v)` statement is a shortcut for `factor(d.log_prob(v))` which conditions the current execution on the _likelihood_ of the value `v` w.r.t. the distribution `d`.\n",
    "In other words, when we write `observe(d, v)` we make the assumption that `v` was sampled from the distribution `d`.\n",
    "\n",
    "### Inference\n",
    "\n",
    "In our example, the domain of the random variable `z` is the entire interval $[0, 1]$. Enumeration of all possible execution is not possible.\n",
    "But, we can use approximate inference scheme to compute the posterior distribution.\n",
    "\n",
    "mu-PPL offers several approximate inference algorithms, ranging from basic importance sampling to Markov Chain Monte Carlo (MCMC), and sequential Monte Carlo (SMC).\n",
    "\n",
    "For instance, we can try importance sampling to approximate the posterior distribution of our model with 1000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ImportanceSampling(num_particles=10000):\n",
    "    dist: Categorical[float] = infer(coin, flips)  # type: ignore\n",
    "    viz(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this simple example, we get a result that is very close to the exact solution: a Beta distribution with parameter `#tail + 1` and `#head + 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "f = np.array(flips)\n",
    "y = beta.pdf(x, np.sum(f) + 1, np.sum(1 - f) + 1)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "The goal of this exercise is to find a linear regression, but rather than finding the best solution, we're looking for a distribution of possible regressions.\n",
    "\n",
    "Consider the following noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "noise = 1\n",
    "lower = 0\n",
    "upper = 10\n",
    "\n",
    "x_obs = np.linspace(lower, upper, N)\n",
    "y_obs = 2 * x_obs - 4  + noise * np.random.randn(N)\n",
    "\n",
    "plt.scatter(x_obs, y_obs, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propose a first linear regression model $y \\sim \\mathcal{N}(ax + b, \\sigma)$.  \n",
    "We want to estimate the parameters $a$, $b$, and $\\sigma$ (noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_obs, y_obs):\n",
    "    # TODO\n",
    "    return [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ImportanceSampling(num_particles=10000):\n",
    "    dist: Empirical[list[float]] = infer(model, x_obs, y_obs)  # type: ignore\n",
    "    coefs_dists = split(dist)\n",
    "    [a_dist, b_dist, sigma_dist] = coefs_dists\n",
    "    [a, b, sigma] = map(lambda d: d.stats()[0], coefs_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now display some samples to check the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    x = np.linspace(lower, upper, 2)\n",
    "    a = a_dist.sample()\n",
    "    b = b_dist.sample()\n",
    "    plt.plot(x, a * x + b, color='blue', alpha=0.1, zorder=0)\n",
    "    \n",
    "plt.scatter(x_obs, y_obs, color='red', zorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probprog-25-26 (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
